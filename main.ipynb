{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aabdollahii/news-headlines-sarcasm-detection?scriptVersionId=264550387\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"3c174ead","metadata":{"papermill":{"duration":0.002805,"end_time":"2025-09-28T19:09:17.473701","exception":false,"start_time":"2025-09-28T19:09:17.470896","status":"completed"},"tags":[]},"source":["<div style=\"background-color:#121212; color:#f5f5f5; font-family:Arial, sans-serif; padding:20px; line-height:1.6; border-radius:10px;\">\n","\n"," <h1 style=\"color:#00bfff; text-align:center;\">Sarcasm Detection in News Headlines</h1>\n","\n"," <h2 style=\"color:#ffd700;\">üìå Introduction</h2>\n","    <p>\n","        Sarcasm is a form of expression where the intended meaning is often the opposite of the literal meaning. Detecting sarcasm in text is a challenging task in Natural Language Processing (NLP) because it often depends on subtle linguistic cues and contextual knowledge. \n","        In this project, we aim to build a robust <strong>binary classification model</strong> that can predict whether a given news headline is sarcastic (<code>1</code>) or not (<code>0</code>).\n","    </p>\n","\n"," <h2 style=\"color:#ffd700;\">üéØ Motivation</h2>\n","    <p>\n","        Understanding sarcasm is essential for improving sentiment analysis, conversational AI systems, and human-computer interaction. \n","        Misinterpreting sarcasm can lead to inaccurate sentiment scores or inappropriate responses in automated systems such as chatbots, virtual assistants, or recommendation models.\n","    </p>\n","\n","<h2 style=\"color:#ffd700;\">üõ† Project Steps</h2>\n","    <ol>\n","        <li><strong>Data Loading & Exploration</strong> ‚Äì Import the dataset, inspect key features, and check distribution of classes.</li>\n","        <li><strong>Data Preprocessing</strong> ‚Äì Tokenize text, remove unwanted characters, apply lemmatization, and handle stopwords.</li>\n","        <li><strong>Feature Representation</strong> ‚Äì Use methods like TF-IDF, Word2Vec, or BERT embeddings to convert text into numerical vectors.</li>\n","        <li><strong>Model Selection & Training</strong> ‚Äì Train classification models (Logistic Regression, SVM, Random Forest, LSTM, Transformers).</li>\n","        <li><strong>Evaluation</strong> ‚Äì Use metrics such as Accuracy, Precision, Recall, and F1-score to assess performance.</li>\n","        <li><strong>Explainability</strong> ‚Äì Apply techniques like SHAP or LIME to interpret model predictions.</li>\n","        <li><strong>Insights & Conclusion</strong> ‚Äì Summarize findings, challenges, and possible improvements.</li>\n","    </ol>\n","\n","<h2 style=\"color:#ffd700;\">üìÇ Dataset Overview</h2>\n","    <p>\n","        The dataset contains approximately <strong>26,000 headlines</strong> collected from news sources. Each headline is labeled with:\n","        <ul>\n","            <li><strong>headline</strong>: The news headline text.</li>\n","            <li><strong>is_sarcastic</strong>: Target variable (<code>1</code> for sarcastic, <code>0</code> for non-sarcastic).</li>\n","            <li><strong>article_link</strong>: Link to the full article (optional).</li>\n","        </ul>\n","        This dataset is relatively clean but may contain duplicates or minimal noise, which will be handled during preprocessing.\n","    </p>\n","\n","<h2 style=\"color:#ffd700;\">üöÄ Expected Outcomes</h2>\n","    <p>\n","        By the end of this project, we expect to have:\n","        <ul>\n","            <li>An accurate sarcasm classifier for news headlines.</li>\n","            <li>Insights into linguistic patterns that contribute to sarcasm.</li>\n","            <li>Visualizations and explainability analyses to make the model more transparent.</li>\n","        </ul>\n","    </p>\n","\n"," <p style=\"text-align:center; color:#00ff7f; font-size:14px; margin-top:30px;\">\n","        <em>‚ÄúThe power of NLP lies not just in understanding words, but in understanding intent.‚Äù</em>\n","    </p>\n","</div>\n"]},{"cell_type":"markdown","id":"0ebabb5b","metadata":{"papermill":{"duration":0.00195,"end_time":"2025-09-28T19:09:17.478002","exception":false,"start_time":"2025-09-28T19:09:17.476052","status":"completed"},"tags":[]},"source":["<div style=\"background-color:#121212; color:#f5f5f5; font-family:Arial, sans-serif; padding:20px; line-height:1.6; border-radius:10px;\">\n","\n"," <h2 style=\"color:#00bfff; text-align:center;\">Step 1: Data Loading & Initial Understanding</h2>\n","\n","<p>\n","        In this stage, we focus on importing the dataset and performing a minor exploration to understand its structure, size, and basic characteristics.\n","        Since we are working with <strong>Sarcasm_Headlines_Dataset_v2.json</strong>, our goal is to ensure the data is read correctly into a format suitable for analysis.\n","    </p>\n","\n","<h3 style=\"color:#ffd700;\">üìå Actions in this Step:</h3>\n","    <ul>\n","        <li>Read the JSON file into a Pandas DataFrame.</li>\n","        <li>Inspect the column names and understand what each one represents.</li>\n","        <li>Check the total number of records (rows) and attributes (columns).</li>\n","        <li>Verify the presence or absence of missing values.</li>\n","        <li>Look at a few sample rows to confirm the structure and quality of the data.</li>\n","        <li>Examine the distribution of the target variable (<code>is_sarcastic</code>).</li>\n","    </ul>\n","\n"," <h3 style=\"color:#ffd700;\">üéØ Purpose of This Step:</h3>\n","    <p>\n","        By gaining an initial understanding of the dataset, we can make informed decisions for preprocessing, feature representation, and model selection in upcoming steps.\n","        This stage lays the foundation for the data cleaning and transformation processes that follow.\n","    </p>\n","\n"," <p style=\"color:#00ff7f; text-align:center; font-size:14px; margin-top:20px;\">\n","        <em>Next, we will move on to data preprocessing and text normalization.</em>\n","    </p>\n","</div>\n"]},{"cell_type":"code","execution_count":1,"id":"0fe517cc","metadata":{"execution":{"iopub.execute_input":"2025-09-28T19:09:17.483416Z","iopub.status.busy":"2025-09-28T19:09:17.48306Z","iopub.status.idle":"2025-09-28T19:09:19.689994Z","shell.execute_reply":"2025-09-28T19:09:19.689108Z"},"papermill":{"duration":2.21165,"end_time":"2025-09-28T19:09:19.691666","exception":false,"start_time":"2025-09-28T19:09:17.480016","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["((28619, 3),\n"," ['is_sarcastic', 'headline', 'article_link'],\n"," is_sarcastic    0\n"," headline        0\n"," article_link    0\n"," dtype: int64,\n"," is_sarcastic\n"," 0    14985\n"," 1    13634\n"," Name: count, dtype: int64,\n"," 47.6396799329117,\n","    is_sarcastic                                           headline  \\\n"," 0             1  thirtysomething scientists unveil doomsday clo...   \n"," 1             0  dem rep. totally nails why congress is falling...   \n"," 2             0  eat your veggies: 9 deliciously different recipes   \n"," 3             1  inclement weather prevents liar from getting t...   \n"," 4             1  mother comes pretty close to using word 'strea...   \n"," \n","                                         article_link  \n"," 0  https://www.theonion.com/thirtysomething-scien...  \n"," 1  https://www.huffingtonpost.com/entry/donna-edw...  \n"," 2  https://www.huffingtonpost.com/entry/eat-your-...  \n"," 3  https://local.theonion.com/inclement-weather-p...  \n"," 4  https://www.theonion.com/mother-comes-pretty-c...  )"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","# Path to dataset\n","path = \"/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset_v2.json\"\n","\n","# Load dataset\n","df = pd.read_json(path, lines=True)\n","\n","# Basic info\n","shape = df.shape\n","columns = df.columns.tolist()\n","missing = df.isnull().sum()\n","class_counts = df['is_sarcastic'].value_counts()\n","sarcastic_ratio = (class_counts[1] / len(df)) * 100\n","\n","# Display some sample rows\n","sample_data = df.head(5)\n","\n","shape, columns, missing, class_counts, sarcastic_ratio, sample_data\n"]},{"cell_type":"markdown","id":"9e508226","metadata":{"papermill":{"duration":0.002127,"end_time":"2025-09-28T19:09:19.696328","exception":false,"start_time":"2025-09-28T19:09:19.694201","status":"completed"},"tags":[]},"source":["<div style=\"background-color:#121212; color:#f5f5f5; font-family:Arial, sans-serif; padding:20px; border-radius:10px; line-height:1.6;\">\n","\n"," <h2 style=\"color:#00bfff; text-align:center;\">Initial Dataset Insights</h2>\n","\n","<p>\n","        After loading <strong>Sarcasm_Headlines_Dataset_v2.json</strong>, we confirmed that the dataset contains \n","        <strong>28,619 rows</strong> and <strong>3 columns</strong>. These columns are:\n","    </p>\n","    <ul>\n","        <li><strong>is_sarcastic</strong> ‚Äì Binary target variable (<code>1</code> for sarcastic headlines, <code>0</code> for non‚Äësarcastic).</li>\n","        <li><strong>headline</strong> ‚Äì Short news headline text.</li>\n","        <li><strong>article_link</strong> ‚Äì URL to the original news article.</li>\n","    </ul>\n","\n"," <h3 style=\"color:#ffd700;\">üìä Missing Values Check</h3>\n","    <p>\n","        No missing values were found in any column, indicating that the dataset is clean and ready for preprocessing.\n","    </p>\n","\n"," <h3 style=\"color:#ffd700;\">‚öñ Class Distribution</h3>\n","    <p>\n","        The dataset is slightly imbalanced:\n","        <ul>\n","            <li><strong>Non‚Äësarcastic (0):</strong> 14,985 entries</li>\n","            <li><strong>Sarcastic (1):</strong> 13,634 entries</li>\n","        </ul>\n","        Sarcastic headlines make up approximately <strong>47.64%</strong> of the total records.\n","    </p>\n","\n"," <h3 style=\"color:#ffd700;\">üîç Sample Headlines</h3>\n","    <p>Here are some examples from the dataset:</p>\n","    <table style=\"border-collapse:collapse; width:100%; border:1px solid #444;\">\n","        <tr style=\"background-color:#1e1e1e;\">\n","            <th style=\"border:1px solid #444; padding:8px;\">is_sarcastic</th>\n","            <th style=\"border:1px solid #444; padding:8px;\">headline</th>\n","            <th style=\"border:1px solid #444; padding:8px;\">article_link</th>\n","        </tr>\n","        <tr>\n","            <td style=\"border:1px solid #444; padding:8px;\">1</td>\n","            <td style=\"border:1px solid #444; padding:8px;\">thirtysomething scientists unveil doomsday clock</td>\n","            <td style=\"border:1px solid #444; padding:8px;\">https://www.theonion.com/thirtysomething-scien...</td>\n","        </tr>\n","        <tr>\n","            <td style=\"border:1px solid #444; padding:8px;\">0</td>\n","            <td style=\"border:1px solid #444; padding:8px;\">dem rep. totally nails why congress is falling apart</td>\n","            <td style=\"border:1px solid #444; padding:8px;\">https://www.huffingtonpost.com/entry/donna-edw...</td>\n","        </tr>\n","        <tr>\n","            <td style=\"border:1px solid #444; padding:8px;\">0</td>\n","            <td style=\"border:1px solid #444; padding:8px;\">eat your veggies: 9 deliciously different recipes</td>\n","            <td style=\"border:1px solid #444; padding:8px;\">https://www.huffingtonpost.com/entry/eat-your-...</td>\n","        </tr>\n","    </table>\n","\n","<p style=\"margin-top:20px; font-size:14px; color:#00ff7f; text-align:center;\">\n","        The dataset is clean and balanced enough for effective model training. \n","        Next, we will proceed to <strong>text preprocessing</strong> and feature representation.\n","    </p>\n","</div>\n"]},{"cell_type":"markdown","id":"fa938a39","metadata":{"papermill":{"duration":0.001999,"end_time":"2025-09-28T19:09:19.700602","exception":false,"start_time":"2025-09-28T19:09:19.698603","status":"completed"},"tags":[]},"source":["<div style=\"background-color:#121212; color:#e0e0e0; padding:20px; font-family:Segoe UI, sans-serif; line-height:1.6; border-radius:8px;\">\n","\n","<h2 style=\"color:#ffcc00;\">üìÑ Text Preprocessing Plan for Sarcasm Detection</h2>\n","\n","<p>To prepare the news headlines dataset for deep learning, we will process the text data so it can be converted into numerical form for the model. Our steps are:</p>\n","\n","<ol style=\"margin-left:20px;\">\n","  <li><strong style=\"color:#ff9966;\">Lowercasing</strong> ‚Äì Convert all headlines to lowercase to ensure uniformity and reduce vocabulary size.</li>\n","  <li><strong style=\"color:#66ccff;\">Punctuation Removal</strong> ‚Äì Eliminate commas, periods, quotes, and other punctuation marks that can add noise.</li>\n","  <li><strong style=\"color:#99ff99;\">Stopword Removal (Optional)</strong> ‚Äì Remove common words like \"the\", \"is\", \"and\" which often carry less semantic weight in classification.</li>\n","  <li><strong style=\"color:#ff6699;\">Tokenization</strong> ‚Äì Use Keras' <code>Tokenizer</code> to map each word to an integer index.</li>\n","  <li><strong style=\"color:#cc99ff;\">Padding</strong> ‚Äì Make all sequences the same length to match the input requirements of neural networks.</li>\n","  <li><strong style=\"color:#ffcc66;\">Train-Test Split</strong> ‚Äì Divide the dataset (e.g., 80% training, 20% testing) to evaluate our model‚Äôs generalization ability.</li>\n","</ol>\n","\n","<p>These preprocessing steps will allow us to feed clean, consistent, numerical representations of headlines into an LSTM/CNN-based sarcasm detection model.</p>\n","\n","</div>\n"]},{"cell_type":"code","execution_count":2,"id":"cff660c3","metadata":{"execution":{"iopub.execute_input":"2025-09-28T19:09:19.706549Z","iopub.status.busy":"2025-09-28T19:09:19.706226Z","iopub.status.idle":"2025-09-28T19:09:38.826961Z","shell.execute_reply":"2025-09-28T19:09:38.82569Z"},"papermill":{"duration":19.12563,"end_time":"2025-09-28T19:09:38.828564","exception":false,"start_time":"2025-09-28T19:09:19.702934","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2025-09-28 19:09:23.181050: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1759086563.400763      13 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1759086563.462823      13 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"name":"stdout","output_type":"stream","text":["Training shape: (22895, 39)\n","Testing shape: (5724, 39)\n","Max sequence length: 39\n"]}],"source":["import re\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","\n","\n","# Function for text cleaning\n","def clean_text(text):\n","    text = text.lower()  # lowercase\n","    text = re.sub(r'[^\\w\\s]', '', text)  # remove punctuation\n","    text = re.sub(r'\\s+', ' ', text).strip()  # remove extra spaces\n","    return text\n","\n","# Apply cleaning\n","df['clean_headline'] = df['headline'].apply(clean_text)\n","\n","# Prepare data and labels\n","X = df['clean_headline'].values\n","y = df['is_sarcastic'].values\n","\n","# Train-test split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Tokenization\n","vocab_size = 10000  \n","tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(X_train)\n","\n","# Convert text to sequences\n","train_sequences = tokenizer.texts_to_sequences(X_train)\n","test_sequences = tokenizer.texts_to_sequences(X_test)\n","\n","# Padding\n","max_length = max(len(seq) for seq in train_sequences)  \n","train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post', truncating='post')\n","test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post', truncating='post')\n","\n","print(f\"Training shape: {train_padded.shape}\")\n","print(f\"Testing shape: {test_padded.shape}\")\n","print(f\"Max sequence length: {max_length}\")\n"]},{"cell_type":"markdown","id":"9a641264","metadata":{"papermill":{"duration":0.0023,"end_time":"2025-09-28T19:09:38.833655","exception":false,"start_time":"2025-09-28T19:09:38.831355","status":"completed"},"tags":[]},"source":["<div style=\"background-color:#121212; color:#e0e0e0; padding:20px; font-family:Segoe UI, sans-serif; border-radius:8px; line-height:1.6;\">\n","\n","<h2 style=\"color:#ffcc00;\">‚úÖ Text Preprocessing Completed</h2>\n","\n","<h3 style=\"color:#66ccff;\">What We Did</h3>\n","<ul style=\"margin-left:20px;\">\n","  <li>üîπ Converted all headlines to <strong>lowercase</strong> for consistency.</li>\n","  <li>üîπ Removed <strong>punctuation marks</strong> and extra spaces to reduce noise.</li>\n","  <li>üîπ Used <strong>Keras Tokenizer</strong> to convert words into integer indices (<em>numerical representation</em>).</li>\n","  <li>üîπ Applied <strong>padding</strong> so all sequences have the same length.</li>\n","  <li>üîπ Split dataset into <strong>training</strong> (80%) and <strong>testing</strong> (20%) sets.</li>\n","</ul>\n","\n","<h3 style=\"color:#99ff99;\">What Happened Now (Results)</h3>\n","<ul style=\"margin-left:20px;\">\n","  <li>üìè The <strong>maximum sequence length</strong> among headlines is <strong>39 words</strong>.</li>\n","  <li>üìä Training set contains <strong>22,895 headlines</strong> padded to length 39.</li>\n","  <li>üìä Testing set contains <strong>5,724 headlines</strong> padded to length 39.</li>\n","  <li>üóÇÔ∏è All the text is now stored in <em>integer‚Äëencoded, fixed‚Äësize arrays</em> ready for neural network input.</li>\n","</ul>\n","\n","<p style=\"margin-top:10px;\">From this point onward, the model will process sequences of integers representing words, instead of raw text. This ensures consistent input dimensions and allows embedding layers or pre-trained word vectors to be applied effectively.</p>\n","\n","</div>\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":30764,"sourceId":533474,"sourceType":"datasetVersion"}],"dockerImageVersionId":31089,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"papermill":{"default_parameters":{},"duration":29.658875,"end_time":"2025-09-28T19:09:41.59829","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-09-28T19:09:11.939415","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}